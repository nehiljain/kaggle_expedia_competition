{"cells":[{"cell_type":"code","source":["%sh /home/ubuntu/databricks/python/bin/pip install langid"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%sh /home/ubuntu/databricks/python/bin/pip install nltk"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import nltk\nnltk.download('wordnet')\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nimport langid\nimport re\nimport string\nsqlContext"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def get_mentions(data_str):\n  result = re.findall(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)\", data_str)\n  return ', '.join(result)\ndef remove_mentions(data_str):\n  return re.sub(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)\", \"\", data_str)\ndef remove_urls(data_str):\n  return re.sub(r\"http\\S+\", \"\", data_str)\n  "],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def check_lang(data_str):\n    predict_lang = langid.classify(data_str)\n    if predict_lang[1] >= .9:\n        language = predict_lang[0]\n    else:\n        language = 'NA'\n    return language"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["def remove_stop_words(data_str):\n    stops = set(stopwords.words(\"english\"))\n    list_pos = 0\n    cleaned_str = ''\n    text = word_tokenize(data_str)\n    for word in text:\n        if word not in stops:\n            if list_pos == 0:\n              cleaner_str = word\n            else:\n              cleaner_str += word\n            list_pos += 1\n    return cleaned_str\n\n    "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%python\ndata_path = \"/FileStore/tables/5po7ek3t1470497347193/IsisFanboy.csv\"\nsqlContext.read.format(\"com.databricks.spark.csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(data_path)\\\n  .registerTempTable(\"isis_signal_twts\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["isis_s = sqlContext.table(\"isis_signal_tweets\")\nisis_n = sqlContext.table(\"isis_noise_tweets\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["isis_n.count()\nisis_s.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["remove_urls_udf = udf(remove_urls, StringType())\nget_mentions_udf = udf(get_mentions, StringType())\nremove_mentions_udf = udf(remove_mentions, StringType())\nremove_stop_words_udf = udf(remove_stop_words, StringType())\ncheck_lang_udf = udf(check_lang, StringType())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["clean_tweets_df = isis_n.withColumn('tweets', remove_urls_udf(isis_n['tweets']))\nclean_tweets_df = clean_tweets_df.withColumn('mentions', get_mentions_udf(clean_tweets_df['tweets']))\nclean_tweets_df = clean_tweets_df.withColumn('tweets', remove_mentions_udf(clean_tweets_df['tweets']))\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["print clean_tweets_df.take(2)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["lang_df = clean_tweets_df.withColumn(\"lang\", check_lang_udf(clean_tweets_df[\"tweets\"]))\nen_df = lang_df.filter(lang_df[\"lang\"] == \"en\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["display(lang_df)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["isis_n.count()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["isis_s.count()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"UbuntuDialogueCorpus","notebookId":1338734463896832},"nbformat":4,"nbformat_minor":0}
